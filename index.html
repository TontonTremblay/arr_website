<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Analog Real Robots (ARR)</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        .authors {
            color: #666;
            margin: 20px 0;
        }
        .abstract {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
        }
        .video-container {
            position: relative;
            padding-bottom: 56.25%;
            height: 0;
            overflow: hidden;
            margin: 20px 0;
        }
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        .citation {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            font-family: monospace;
            white-space: pre;
            overflow-x: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Analog Real Robots (ARR)</h1>
        
        <div class="authors">
            <p>Valts Blukis, Balakumar Sundaralingam, Alex Zook, Stan Birchfield, Jonathan Tremblay</p>
        </div>

        <div class="abstract">
            <p>Analog Real Robots (ARR) is a framework that combines Vision-Language Models (VLMs) and Large Language Models (LLMs) to enable dynamic scene understanding and adaptive task execution for robotic manipulation in complex environments. It excels in recognizing unseen objects, reasoning spatially, and generating robust, adaptable plans, outperforming existing methods.</p>
        </div>

        <h2>Paper</h2>
        <p><a href="https://www.dropbox.com/scl/fi/vf788bgoppqawtm6g2193/robot.pdf?rlkey=enpn004hbm9mfpjvevhwdwcqj&dl=0" target="_blank">Download Paper</a></p>

        <h2>Video</h2>
        <div class="video-container">
            <iframe src="https://www.youtube.com/embed/A89Fdm0wAzk" 
                    frameborder="0" 
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                    allowfullscreen>
            </iframe>
        </div>

        <h2>Citation</h2>
        <div class="citation">@article{blukis2024analog,
    author = {Blukis, Valts and Sundaralingam, Balakumar and Zook, Alex and Birchfield, Stan and Tremblay, Jonathan},
    title = {Analog Real Robots},
    year = {2024},
    url = {analogrealrobots.pages.dev},
    howpublished = {\url{analogrealrobots.pages.dev}},
    note = {Accessed: 2024-11-26}
}</div>
    </div>
</body>
</html>
